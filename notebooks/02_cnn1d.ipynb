{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f2f9f3",
   "metadata": {},
   "source": [
    "### Simpler Model: 1D Convolutional Neural Network (CNN)\n",
    "\n",
    "To complement the baseline STFT + Conv2D + RNN model, we implemented a lightweight 1D CNN that operates directly on raw ECG signals. This model is more straightforward, easier to train, and more stable in early training phases.\n",
    "\n",
    "#### Architecture Overview\n",
    "The model consists of a stack of three 1D convolutional blocks followed by a global average pooling and a fully connected classifier:\n",
    "- Conv1d → BatchNorm1d → ReLU → MaxPool1d\n",
    "- Conv1d → BatchNorm1d → ReLU → MaxPool1d\n",
    "- Conv1d → BatchNorm1d → ReLU → AdaptiveAvgPool1d\n",
    "- Linear → output logits for 4 classes\n",
    "\n",
    "Each raw ECG signal is zero-padded to the length of the longest signal in the batch to ensure compatibility with batch processing.\n",
    "\n",
    "#### Why 1D CNN?\n",
    "1D CNNs are well-suited for time series tasks like ECG classification due to their ability to extract local patterns (e.g., QRS complexes) efficiently across the signal. Unlike the baseline, this model avoids frequency-domain transformation and recurrent layers, resulting in:\n",
    "- Faster training\n",
    "- Lower complexity\n",
    "- Competitive performance, especially with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea22f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ba54bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cuzdu/Desktop/early-alzhemir-detection/env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 208.3s\n",
      "  Train Loss: 1.3108 | Acc: 0.3251 | F1: 0.2754\n",
      "  Val   Loss: 1.2417 | Acc: 0.3244 | F1: 0.2342\n",
      "Epoch 02 | Time: 256.7s\n",
      "  Train Loss: 1.2176 | Acc: 0.3585 | F1: 0.2943\n",
      "  Val   Loss: 1.1852 | Acc: 0.3083 | F1: 0.2619\n",
      "Epoch 03 | Time: 237.1s\n",
      "  Train Loss: 1.1396 | Acc: 0.3779 | F1: 0.3196\n",
      "  Val   Loss: 1.1582 | Acc: 0.3252 | F1: 0.3055\n",
      "Epoch 04 | Time: 220.7s\n",
      "  Train Loss: 1.1171 | Acc: 0.3759 | F1: 0.3291\n",
      "  Val   Loss: 1.1204 | Acc: 0.5526 | F1: 0.3832\n",
      "Epoch 05 | Time: 243.2s\n",
      "  Train Loss: 1.1039 | Acc: 0.3868 | F1: 0.3317\n",
      "  Val   Loss: 1.5044 | Acc: 0.2961 | F1: 0.2528\n",
      "Epoch 06 | Time: 250.8s\n",
      "  Train Loss: 1.0864 | Acc: 0.4111 | F1: 0.3500\n",
      "  Val   Loss: 1.1038 | Acc: 0.2888 | F1: 0.2973\n",
      "Epoch 07 | Time: 221.2s\n",
      "  Train Loss: 1.0716 | Acc: 0.4099 | F1: 0.3523\n",
      "  Val   Loss: 1.0887 | Acc: 0.4474 | F1: 0.3605\n",
      "Epoch 08 | Time: 229.8s\n",
      "  Train Loss: 1.0386 | Acc: 0.4439 | F1: 0.3693\n",
      "  Val   Loss: 1.0747 | Acc: 0.3932 | F1: 0.3305\n",
      "Epoch 09 | Time: 230.9s\n",
      "  Train Loss: 1.0337 | Acc: 0.4538 | F1: 0.3749\n",
      "  Val   Loss: 1.0758 | Acc: 0.4474 | F1: 0.3748\n",
      "Epoch 10 | Time: 229.8s\n",
      "  Train Loss: 1.0481 | Acc: 0.4524 | F1: 0.3777\n",
      "  Val   Loss: 1.0643 | Acc: 0.3875 | F1: 0.3512\n",
      "Epoch 11 | Time: 230.4s\n",
      "  Train Loss: 1.0293 | Acc: 0.4645 | F1: 0.3914\n",
      "  Val   Loss: 1.0440 | Acc: 0.4668 | F1: 0.3732\n",
      "Epoch 12 | Time: 236.4s\n",
      "  Train Loss: 1.0180 | Acc: 0.4685 | F1: 0.3910\n",
      "  Val   Loss: 1.0481 | Acc: 0.4094 | F1: 0.3652\n",
      "Epoch 13 | Time: 236.5s\n",
      "  Train Loss: 1.0148 | Acc: 0.4730 | F1: 0.3925\n",
      "  Val   Loss: 1.0420 | Acc: 0.3892 | F1: 0.3523\n",
      "Epoch 14 | Time: 246.9s\n",
      "  Train Loss: 1.0088 | Acc: 0.4716 | F1: 0.3964\n",
      "  Val   Loss: 1.0360 | Acc: 0.5057 | F1: 0.4008\n",
      "Epoch 15 | Time: 222.9s\n",
      "  Train Loss: 1.0033 | Acc: 0.4959 | F1: 0.4161\n",
      "  Val   Loss: 1.0288 | Acc: 0.5000 | F1: 0.4078\n",
      "Epoch 16 | Time: 206.7s\n",
      "  Train Loss: 1.0014 | Acc: 0.4936 | F1: 0.4096\n",
      "  Val   Loss: 1.0294 | Acc: 0.4620 | F1: 0.3973\n",
      "Epoch 17 | Time: 210.6s\n",
      "  Train Loss: 1.0079 | Acc: 0.4946 | F1: 0.4101\n",
      "  Val   Loss: 1.0319 | Acc: 0.4838 | F1: 0.4149\n",
      "Epoch 18 | Time: 211.0s\n",
      "  Train Loss: 1.0044 | Acc: 0.4849 | F1: 0.4045\n",
      "  Val   Loss: 1.0298 | Acc: 0.5307 | F1: 0.4229\n",
      "Epoch 19 | Time: 217.3s\n",
      "  Train Loss: 1.0039 | Acc: 0.4843 | F1: 0.4063\n",
      "  Val   Loss: 1.0352 | Acc: 0.5170 | F1: 0.4099\n",
      "Epoch 20 | Time: 220.5s\n",
      "  Train Loss: 0.9971 | Acc: 0.5009 | F1: 0.4198\n",
      "  Val   Loss: 1.0281 | Acc: 0.5348 | F1: 0.4311\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from src.ecg_dataset import ECGDataset, prep_batch\n",
    "from src.cnn1d import CNN1DModel\n",
    "from src.train_utils import train_one_epoch, evaluate\n",
    "from src.train import train_model\n",
    "from src.parser import read_zip_binary\n",
    "\n",
    "# load data (same as before)\n",
    "train_idx = np.load(\"../data/train_idx.npy\")\n",
    "val_idx = np.load(\"../data/val_idx.npy\")\n",
    "\n",
    "X_train = read_zip_binary(\"../data/X_train.zip\")\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\", header=None)\n",
    "y_train.columns = [\"y\"]\n",
    "\n",
    "train_dataset = ECGDataset(X_train, y_train, indices=train_idx)\n",
    "val_dataset = ECGDataset(X_train, y_train, indices=val_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=prep_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=prep_batch)\n",
    "\n",
    "# device is cpu by default but added this line (instead of hardcoding cpu string) since you may be using cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# weights are added to counter class imbalance\n",
    "# idea is basically penalizing the rare classes more in order to classify them correctly\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=[0, 1, 2, 3], y=y_train[\"y\"])\n",
    "weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# load the 1d cnn model into device -- similar practices as always\n",
    "model = CNN1DModel(n_classes=4).to(device)\n",
    "# TODO : maybe we can work more on learning rate and find a good balance between lr and # of epochs\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "# enter the training loop -- train_model returns the best model in the end\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    num_epochs=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
