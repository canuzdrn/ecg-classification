{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f2f9f3",
   "metadata": {},
   "source": [
    "### Simpler Model: 1D Convolutional Neural Network (CNN)\n",
    "\n",
    "To complement the baseline STFT + Conv2D + RNN model, we implemented a lightweight 1D CNN that operates directly on raw ECG signals. This model is more straightforward, easier to train, and more stable in early training phases.\n",
    "\n",
    "#### Architecture Overview\n",
    "The model consists of a stack of three 1D convolutional blocks followed by a global average pooling and a fully connected classifier:\n",
    "- Conv1d → BatchNorm1d → ReLU → MaxPool1d\n",
    "- Conv1d → BatchNorm1d → ReLU → MaxPool1d\n",
    "- Conv1d → BatchNorm1d → ReLU → AdaptiveAvgPool1d\n",
    "- Linear → output logits for 4 classes\n",
    "\n",
    "Each raw ECG signal is zero-padded to the length of the longest signal in the batch to ensure compatibility with batch processing.\n",
    "\n",
    "#### Why 1D CNN?\n",
    "1D CNNs are well-suited for time series tasks like ECG classification due to their ability to extract local patterns (e.g., QRS complexes) efficiently across the signal. Unlike the baseline, this model avoids frequency-domain transformation and recurrent layers, resulting in:\n",
    "- Faster training\n",
    "- Lower complexity\n",
    "- Competitive performance, especially with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea22f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ba54bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 132.1s\n",
      "  Train Loss: 1.3753 | Acc: 0.2444 | F1: 0.1585\n",
      "  Val   Loss: 1.3518 | Acc: 0.2581 | F1: 0.1736\n",
      "Epoch 02 | Time: 132.1s\n",
      "  Train Loss: 1.3410 | Acc: 0.2764 | F1: 0.2349\n",
      "  Val   Loss: 1.3181 | Acc: 0.3107 | F1: 0.2855\n",
      "Epoch 03 | Time: 132.7s\n",
      "  Train Loss: 1.3010 | Acc: 0.3700 | F1: 0.3079\n",
      "  Val   Loss: 1.2716 | Acc: 0.2597 | F1: 0.2430\n",
      "Epoch 04 | Time: 131.8s\n",
      "  Train Loss: 1.2518 | Acc: 0.3073 | F1: 0.2820\n",
      "  Val   Loss: 1.2195 | Acc: 0.2314 | F1: 0.2336\n",
      "Epoch 05 | Time: 132.7s\n",
      "  Train Loss: 1.2090 | Acc: 0.3761 | F1: 0.3048\n",
      "  Val   Loss: 1.1901 | Acc: 0.3875 | F1: 0.3117\n",
      "Epoch 06 | Time: 132.2s\n",
      "  Train Loss: 1.1728 | Acc: 0.3399 | F1: 0.3008\n",
      "  Val   Loss: 1.1635 | Acc: 0.4992 | F1: 0.3131\n",
      "Epoch 07 | Time: 135.4s\n",
      "  Train Loss: 1.1489 | Acc: 0.4062 | F1: 0.3274\n",
      "  Val   Loss: 1.1350 | Acc: 0.4094 | F1: 0.3438\n",
      "Epoch 08 | Time: 132.8s\n",
      "  Train Loss: 1.1270 | Acc: 0.4117 | F1: 0.3352\n",
      "  Val   Loss: 1.1522 | Acc: 0.5324 | F1: 0.3362\n",
      "Epoch 09 | Time: 132.2s\n",
      "  Train Loss: 1.1229 | Acc: 0.4022 | F1: 0.3274\n",
      "  Val   Loss: 1.1142 | Acc: 0.4968 | F1: 0.3576\n",
      "Epoch 10 | Time: 131.7s\n",
      "  Train Loss: 1.0925 | Acc: 0.4255 | F1: 0.3482\n",
      "  Val   Loss: 1.1209 | Acc: 0.1626 | F1: 0.1805\n",
      "Epoch 11 | Time: 132.1s\n",
      "  Train Loss: 1.0858 | Acc: 0.4129 | F1: 0.3487\n",
      "  Val   Loss: 1.1183 | Acc: 0.3042 | F1: 0.2694\n",
      "Epoch 12 | Time: 132.4s\n",
      "  Train Loss: 1.0752 | Acc: 0.4147 | F1: 0.3420\n",
      "  Val   Loss: 1.1658 | Acc: 0.5275 | F1: 0.3705\n",
      "Epoch 13 | Time: 131.0s\n",
      "  Train Loss: 1.0678 | Acc: 0.4370 | F1: 0.3618\n",
      "  Val   Loss: 1.1282 | Acc: 0.3948 | F1: 0.2951\n",
      "Epoch 14 | Time: 131.8s\n",
      "  Train Loss: 1.0633 | Acc: 0.4378 | F1: 0.3681\n",
      "  Val   Loss: 1.2923 | Acc: 0.3398 | F1: 0.2900\n",
      "Epoch 15 | Time: 132.5s\n",
      "  Train Loss: 1.0571 | Acc: 0.4404 | F1: 0.3719\n",
      "  Val   Loss: 1.0492 | Acc: 0.4134 | F1: 0.3510\n",
      "Epoch 16 | Time: 131.8s\n",
      "  Train Loss: 1.0628 | Acc: 0.4443 | F1: 0.3700\n",
      "  Val   Loss: 1.0569 | Acc: 0.3236 | F1: 0.3162\n",
      "Epoch 17 | Time: 132.4s\n",
      "  Train Loss: 1.0372 | Acc: 0.4507 | F1: 0.3821\n",
      "  Val   Loss: 1.0678 | Acc: 0.4474 | F1: 0.3822\n",
      "Epoch 18 | Time: 132.3s\n",
      "  Train Loss: 1.0402 | Acc: 0.4532 | F1: 0.3840\n",
      "  Val   Loss: 1.0296 | Acc: 0.5526 | F1: 0.4433\n",
      "Epoch 19 | Time: 132.0s\n",
      "  Train Loss: 1.0324 | Acc: 0.4685 | F1: 0.3959\n",
      "  Val   Loss: 1.0896 | Acc: 0.4029 | F1: 0.3284\n",
      "Epoch 20 | Time: 132.2s\n",
      "  Train Loss: 1.0377 | Acc: 0.4511 | F1: 0.3763\n",
      "  Val   Loss: 1.0830 | Acc: 0.3625 | F1: 0.3190\n",
      "Epoch 21 | Time: 132.5s\n",
      "  Train Loss: 1.0333 | Acc: 0.4673 | F1: 0.3929\n",
      "  Val   Loss: 1.0568 | Acc: 0.4660 | F1: 0.3896\n",
      "Epoch 22 | Time: 132.7s\n",
      "  Train Loss: 1.0146 | Acc: 0.4691 | F1: 0.3999\n",
      "  Val   Loss: 1.0038 | Acc: 0.5388 | F1: 0.4454\n",
      "Epoch 23 | Time: 131.6s\n",
      "  Train Loss: 1.0149 | Acc: 0.4704 | F1: 0.3980\n",
      "  Val   Loss: 1.0295 | Acc: 0.5413 | F1: 0.4353\n",
      "Epoch 24 | Time: 132.8s\n",
      "  Train Loss: 1.0132 | Acc: 0.4870 | F1: 0.4136\n",
      "  Val   Loss: 0.9871 | Acc: 0.5469 | F1: 0.4260\n",
      "Epoch 25 | Time: 132.3s\n",
      "  Train Loss: 1.0028 | Acc: 0.4783 | F1: 0.4075\n",
      "  Val   Loss: 1.0333 | Acc: 0.5057 | F1: 0.3734\n",
      "Epoch 26 | Time: 132.2s\n",
      "  Train Loss: 1.0044 | Acc: 0.4855 | F1: 0.4087\n",
      "  Val   Loss: 1.0277 | Acc: 0.5752 | F1: 0.4556\n",
      "Epoch 27 | Time: 133.3s\n",
      "  Train Loss: 0.9908 | Acc: 0.5052 | F1: 0.4245\n",
      "  Val   Loss: 0.9862 | Acc: 0.4951 | F1: 0.4287\n",
      "Epoch 28 | Time: 132.9s\n",
      "  Train Loss: 0.9793 | Acc: 0.4959 | F1: 0.4183\n",
      "  Val   Loss: 0.9818 | Acc: 0.5485 | F1: 0.4556\n",
      "Epoch 29 | Time: 132.9s\n",
      "  Train Loss: 0.9828 | Acc: 0.5009 | F1: 0.4256\n",
      "  Val   Loss: 0.9622 | Acc: 0.4644 | F1: 0.4137\n",
      "Epoch 30 | Time: 132.9s\n",
      "  Train Loss: 0.9750 | Acc: 0.5128 | F1: 0.4362\n",
      "  Val   Loss: 0.9668 | Acc: 0.5526 | F1: 0.4555\n",
      "Epoch 31 | Time: 166.0s\n",
      "  Train Loss: 0.9543 | Acc: 0.5106 | F1: 0.4363\n",
      "  Val   Loss: 0.9645 | Acc: 0.4773 | F1: 0.4214\n",
      "Epoch 32 | Time: 132.4s\n",
      "  Train Loss: 0.9627 | Acc: 0.5141 | F1: 0.4435\n",
      "  Val   Loss: 0.9730 | Acc: 0.4320 | F1: 0.3822\n",
      "Epoch 33 | Time: 132.1s\n",
      "  Train Loss: 0.9503 | Acc: 0.5114 | F1: 0.4394\n",
      "  Val   Loss: 0.9623 | Acc: 0.4838 | F1: 0.4371\n",
      "Epoch 34 | Time: 132.8s\n",
      "  Train Loss: 0.9564 | Acc: 0.5203 | F1: 0.4489\n",
      "  Val   Loss: 0.9599 | Acc: 0.5542 | F1: 0.4824\n",
      "Epoch 35 | Time: 131.5s\n",
      "  Train Loss: 0.9500 | Acc: 0.5321 | F1: 0.4555\n",
      "  Val   Loss: 0.9589 | Acc: 0.4951 | F1: 0.4104\n",
      "Epoch 36 | Time: 132.1s\n",
      "  Train Loss: 0.9406 | Acc: 0.5306 | F1: 0.4585\n",
      "  Val   Loss: 0.9501 | Acc: 0.4741 | F1: 0.4282\n",
      "Epoch 37 | Time: 132.3s\n",
      "  Train Loss: 0.9353 | Acc: 0.5313 | F1: 0.4530\n",
      "  Val   Loss: 0.9365 | Acc: 0.5372 | F1: 0.4627\n",
      "Epoch 38 | Time: 132.3s\n",
      "  Train Loss: 0.9243 | Acc: 0.5278 | F1: 0.4542\n",
      "  Val   Loss: 0.9270 | Acc: 0.5744 | F1: 0.4939\n",
      "Epoch 39 | Time: 133.1s\n",
      "  Train Loss: 0.9200 | Acc: 0.5452 | F1: 0.4727\n",
      "  Val   Loss: 0.9346 | Acc: 0.5283 | F1: 0.4608\n",
      "Epoch 40 | Time: 131.0s\n",
      "  Train Loss: 0.9315 | Acc: 0.5341 | F1: 0.4592\n",
      "  Val   Loss: 0.9293 | Acc: 0.4474 | F1: 0.4167\n",
      "Epoch 41 | Time: 131.1s\n",
      "  Train Loss: 0.9225 | Acc: 0.5387 | F1: 0.4718\n",
      "  Val   Loss: 0.9223 | Acc: 0.5413 | F1: 0.4673\n",
      "Epoch 42 | Time: 132.8s\n",
      "  Train Loss: 0.9062 | Acc: 0.5519 | F1: 0.4754\n",
      "  Val   Loss: 0.9167 | Acc: 0.5081 | F1: 0.4529\n",
      "Epoch 43 | Time: 132.1s\n",
      "  Train Loss: 0.9066 | Acc: 0.5472 | F1: 0.4737\n",
      "  Val   Loss: 0.9215 | Acc: 0.5057 | F1: 0.4638\n",
      "Epoch 44 | Time: 132.5s\n",
      "  Train Loss: 0.9094 | Acc: 0.5442 | F1: 0.4716\n",
      "  Val   Loss: 0.9140 | Acc: 0.5769 | F1: 0.4914\n",
      "Epoch 45 | Time: 132.2s\n",
      "  Train Loss: 0.9030 | Acc: 0.5539 | F1: 0.4800\n",
      "  Val   Loss: 0.9134 | Acc: 0.5348 | F1: 0.4761\n",
      "Epoch 46 | Time: 132.5s\n",
      "  Train Loss: 0.9074 | Acc: 0.5576 | F1: 0.4816\n",
      "  Val   Loss: 0.9102 | Acc: 0.5631 | F1: 0.4914\n",
      "Epoch 47 | Time: 132.7s\n",
      "  Train Loss: 0.9010 | Acc: 0.5582 | F1: 0.4815\n",
      "  Val   Loss: 0.9111 | Acc: 0.5631 | F1: 0.4867\n",
      "Epoch 48 | Time: 132.6s\n",
      "  Train Loss: 0.8951 | Acc: 0.5537 | F1: 0.4778\n",
      "  Val   Loss: 0.9083 | Acc: 0.5388 | F1: 0.4708\n",
      "Epoch 49 | Time: 132.3s\n",
      "  Train Loss: 0.8953 | Acc: 0.5588 | F1: 0.4832\n",
      "  Val   Loss: 0.9114 | Acc: 0.5688 | F1: 0.4907\n",
      "Epoch 50 | Time: 131.8s\n",
      "  Train Loss: 0.8999 | Acc: 0.5549 | F1: 0.4785\n",
      "  Val   Loss: 0.9084 | Acc: 0.5526 | F1: 0.4766\n",
      "Training done, model is saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from src.ecg_dataset import ECGDataset, prep_batch\n",
    "from src.cnn1d import CNN1DModel\n",
    "from src.train import train_model\n",
    "from src.parser import read_zip_binary\n",
    "\n",
    "# load data (same as before)\n",
    "train_idx = np.load(\"../data/train_idx.npy\")\n",
    "val_idx = np.load(\"../data/val_idx.npy\")\n",
    "\n",
    "X_train = read_zip_binary(\"../data/X_train.zip\")\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\", header=None)\n",
    "y_train.columns = [\"y\"]\n",
    "\n",
    "train_dataset = ECGDataset(X_train, y_train, indices=train_idx)\n",
    "val_dataset = ECGDataset(X_train, y_train, indices=val_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=prep_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=prep_batch)\n",
    "\n",
    "# device is cpu by default but added this line (instead of hardcoding cpu string) since you may be using cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# weights are added to counter class imbalance\n",
    "# idea is basically penalizing the rare classes more in order to classify them correctly\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=np.array([0, 1, 2, 3]), y=y_train[\"y\"])\n",
    "\n",
    "weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# load the 1d cnn model into device -- similar practices as always\n",
    "model = CNN1DModel(n_classes=4).to(device)\n",
    "# TODO : maybe we can work more on learning rate and find a good balance between lr and # of epochs\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "# enter the training loop -- train_model returns the best model in the end\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    num_epochs=50\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eeg-amls)",
   "language": "python",
   "name": "eeg-amls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
