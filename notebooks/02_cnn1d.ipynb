{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f2f9f3",
   "metadata": {},
   "source": [
    "### Simpler Model: 1D Convolutional Neural Network (CNN)\n",
    "\n",
    "To complement the baseline STFT + Conv2D + RNN model, we implemented a lightweight 1D CNN that operates directly on raw ECG signals. This model is more straightforward, easier to train, and more stable in early training phases.\n",
    "\n",
    "#### Architecture Overview\n",
    "The model consists of a stack of three 1D convolutional blocks followed by a global average pooling and a fully connected classifier:\n",
    "- Conv1d → BatchNorm1d → ReLU → MaxPool1d\n",
    "- Conv1d → BatchNorm1d → ReLU → MaxPool1d\n",
    "- Conv1d → BatchNorm1d → ReLU → AdaptiveAvgPool1d\n",
    "- Linear → output logits for 4 classes\n",
    "\n",
    "Each raw ECG signal is zero-padded to the length of the longest signal in the batch to ensure compatibility with batch processing.\n",
    "\n",
    "#### Why 1D CNN?\n",
    "1D CNNs are well-suited for time series tasks like ECG classification due to their ability to extract local patterns (e.g., QRS complexes) efficiently across the signal. Unlike the baseline, this model avoids frequency-domain transformation and recurrent layers, resulting in:\n",
    "- Faster training\n",
    "- Lower complexity\n",
    "- Competitive performance, especially with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea22f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba54bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predictions: (array([0, 1, 2, 3]), array([  1, 320, 843,  72]))\n",
      "Epoch 01 | Time: 173.9s\n",
      "  Train Loss: 1.3019 | Acc: 0.4677 | F1: 0.3166\n",
      "  Val   Loss: 1.1883 | Acc: 0.2662 | F1: 0.2936\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([725, 329,  50, 132]))\n",
      "Epoch 02 | Time: 192.0s\n",
      "  Train Loss: 1.2195 | Acc: 0.4196 | F1: 0.3387\n",
      "  Val   Loss: 1.1265 | Acc: 0.4684 | F1: 0.3588\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([239, 259, 546, 192]))\n",
      "Epoch 03 | Time: 190.4s\n",
      "  Train Loss: 1.1963 | Acc: 0.3975 | F1: 0.3270\n",
      "  Val   Loss: 1.1036 | Acc: 0.3301 | F1: 0.3193\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([135, 368, 588, 145]))\n",
      "Epoch 04 | Time: 192.6s\n",
      "  Train Loss: 1.1760 | Acc: 0.3838 | F1: 0.3292\n",
      "  Val   Loss: 1.1070 | Acc: 0.2921 | F1: 0.3035\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([744, 237, 159,  96]))\n",
      "Epoch 05 | Time: 194.6s\n",
      "  Train Loss: 1.1639 | Acc: 0.3747 | F1: 0.3219\n",
      "  Val   Loss: 1.1116 | Acc: 0.5057 | F1: 0.4175\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([613, 248, 244, 131]))\n",
      "Epoch 06 | Time: 199.8s\n",
      "  Train Loss: 1.1459 | Acc: 0.3818 | F1: 0.3275\n",
      "  Val   Loss: 1.0717 | Acc: 0.4782 | F1: 0.4070\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([606, 397,  78, 155]))\n",
      "Epoch 07 | Time: 194.4s\n",
      "  Train Loss: 1.1200 | Acc: 0.4305 | F1: 0.3560\n",
      "  Val   Loss: 1.0580 | Acc: 0.4256 | F1: 0.3479\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([372, 478, 218, 168]))\n",
      "Epoch 08 | Time: 196.2s\n",
      "  Train Loss: 1.1120 | Acc: 0.3870 | F1: 0.3376\n",
      "  Val   Loss: 1.0438 | Acc: 0.3576 | F1: 0.3378\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([152, 619, 363, 102]))\n",
      "Epoch 09 | Time: 222.7s\n",
      "  Train Loss: 1.0982 | Acc: 0.4131 | F1: 0.3503\n",
      "  Val   Loss: 1.0645 | Acc: 0.2791 | F1: 0.3233\n",
      "Unique predictions: (array([0, 1, 2, 3]), array([467, 565,  70, 134]))\n",
      "Epoch 10 | Time: 231.2s\n",
      "  Train Loss: 1.0862 | Acc: 0.4204 | F1: 0.3540\n",
      "  Val   Loss: 1.0469 | Acc: 0.3843 | F1: 0.3444\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from src.ecg_dataset import ECGDataset, prep_batch\n",
    "from src.cnn1d import CNN1DModel\n",
    "from src.train_utils import train_one_epoch, evaluate\n",
    "from src.train import train_model\n",
    "from src.parser import read_zip_binary\n",
    "\n",
    "# load data (same as before)\n",
    "train_idx = np.load(\"../data/train_idx.npy\")\n",
    "val_idx = np.load(\"../data/val_idx.npy\")\n",
    "\n",
    "X_train = read_zip_binary(\"../data/X_train.zip\")\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\", header=None)\n",
    "y_train.columns = [\"y\"]\n",
    "\n",
    "train_dataset = ECGDataset(X_train, y_train, indices=train_idx)\n",
    "val_dataset = ECGDataset(X_train, y_train, indices=val_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=prep_batch)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=prep_batch)\n",
    "\n",
    "# device is cpu by default but added this line (instead of hardcoding cpu string) since you may be using cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# weights are added to counter class imbalance\n",
    "# idea is basically penalizing the rare classes more in order to classify them correctly\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=[0, 1, 2, 3], y=y_train[\"y\"])\n",
    "weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# load the 1d cnn model into device -- similar practices as always\n",
    "model = CNN1DModel(n_classes=4).to(device)\n",
    "# TODO : maybe we can work more on learning rate and find a good balance between lr and # of epochs\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-3)\n",
    "\n",
    "# enter the training loop -- train_model returns the best model in the end\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    num_epochs=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
